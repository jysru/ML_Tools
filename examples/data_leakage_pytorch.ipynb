{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import mltools.dataset as dtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a dataset from random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.RandomDataset object at 0x0000017E54866F70>\n"
     ]
    }
   ],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, n: int, m: int, N: int, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self._n = n\n",
    "        self._m = m\n",
    "        self._N = N\n",
    "        self.device = device\n",
    "        self.__make()\n",
    "        \n",
    "    def __make(self):\n",
    "        self._X = torch.rand([self._N, self._n], device=self.device)\n",
    "        self._Y = torch.rand([self._N, self._m], device=self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self._X[idx, :], self._Y[idx, :]       \n",
    "\n",
    "\n",
    "unbatched_dset = RandomDataset(5, 2, 1000)\n",
    "print(unbatched_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and seed for reproducibility\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# Split the dataset into train and val -> Those should not have leakage\n",
    "train_set, val_set = torch.utils.data.random_split(unbatched_dset, [0.8, 0.2], generator=generator)\n",
    "\n",
    "# Split the val dataset into two test sets -> They should have leakage with the val subset\n",
    "test_set1, test_set2 = torch.utils.data.random_split(val_set, [0.5, 0.5], generator=generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders from subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader1 = torch.utils.data.DataLoader(test_set1, batch_size=batch_size, shuffle=False)\n",
    "test_loader2 = torch.utils.data.DataLoader(test_set2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data leakage detected between train and val.\n",
      "No data leakage detected between train and test1.\n",
      "No data leakage detected between train and test2.\n",
      "Data leakage detected between val and test1: 100 common elements found.\n",
      "Percentage of overlapping elements: 33.33%\n",
      "Data leakage detected between val and test2: 100 common elements found.\n",
      "Percentage of overlapping elements: 33.33%\n",
      "No data leakage detected between test1 and test2.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    dtools.torch_are_dataloaders_leaking(\n",
    "    dict(\n",
    "        train = train_loader,\n",
    "        val = val_loader,\n",
    "        test1 = test_loader1,\n",
    "        test2 = test_loader2,\n",
    "    )\n",
    ")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
